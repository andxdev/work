You will be provided with two versions of the source code for the same model, along with the corresponding model documentation. Your tasks are to extract and analyse the material thoroughly and present your findings in a clear, technically rigorous, and well-written narrative.
Begin by extracting the code from both documents and automatically identifying the programming language or languages used. Once this is established, produce a detailed explanation of the code written in continuous prose and structured as a technical report. This explanation should describe the purpose and overall functionality of the program or module, the organisation and responsibilities of its main components, the significant processing steps or algorithms involved, the expected inputs and outputs (including their data types or formats), any underlying assumptions or prerequisites needed to run the code, and all relevant dependencies such as external libraries, APIs, environment variables, configuration files, external functions, or required runtime environments. The discussion should be rich, coherent, and suitable for stakeholders, but it must not rely on bullet points or segmented lists except where explicitly requested later in the prompt.
After summarising the functionality, perform a unified diff between the two versions of the code. Identify and analyse all modifications, beginning with a clear quantitative overview of the total number of changed lines, distinguishing between additions, removals, and modifications. Present this section as flowing prose rather than as a list. For each individual change, if the total number of changes is fifteen or fewer, provide an explanation that references the exact line number and describes what was added, removed, or altered. Each explanation should also classify the nature of the change (for example, feature addition, refactor, bug fix, breaking change) and include a brief risk assessment (low, medium, or high). These explanations should be concise but sufficiently detailed to convey intent, context, and implications. If there are more than fifteen changes, focus on the three to five most significant or potentially risky modifications individually, while offering an aggregated summary of the remaining edits. Ensure that the narrative preserves context, supports informed review, and maintains a formal, documentation-ready tone.
Next, review both versions of the code and flag any items that may require governance or compliance oversight. This includes, but is not limited to, threshold values or hard-coded constants, magic numbers, fixed random seeds or other randomisation parameters, feature flags or conditional toggles, date or time-based logic, time-window assumptions, or any other elements that could introduce model governance concerns. Discuss these observations directly in prose.
Finally, propose test cases that would meaningfully evaluate the behaviour of the system. Provide three happy-path scenarios covering normal expected behaviour and four edge-case scenarios addressing boundary conditions, invalid inputs, and error handling. These seven scenarios may be listed explicitly, as they represent test specifications.
Throughout the analysis, write in a formal, coherent narrative style. Except for the required list of test cases, avoid bullet points, numbered lists, or fragmented formatting. The final output should read as a polished, comprehensive document suitable for inclusion in formal technical documentation or change-control review.
